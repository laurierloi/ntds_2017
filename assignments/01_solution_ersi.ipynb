{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NTDS assignment 1: Solution\n",
    "[Effrosyni Simou](http://lts4.epfl.ch/simou), *PhD Student*, [EPFL](http://epfl.ch) [LTS4](http://lts4.epfl.ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective of Exercise\n",
    "The aim of this exercise is to learn how to create your own, real network using data collected from the Internet and then to discover some properties of the collected network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    "You might want to have a look at the following resources before starting:\n",
    "\n",
    "* [Twitter REST API](https://dev.twitter.com/rest/public)\n",
    "* [Tweepy Documentation](http://tweepy.readthedocs.io/en/v3.5.0/)\n",
    "* [Tutorial \"Mining Twitter data with Python\"](https://marcobonzanini.com/2015/03/02/mining-twitter-data-with-python-part-1/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Collect a Twitter Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to collect data from Twitter you will need to generate access tokens.  To do this you will need to register a [client application with Twitter](https://apps.twitter.com/). Once you are done you should have your tokens. You can now create a `credentials.ini` file as follows:\n",
    "```\n",
    "[twitter]\n",
    "consumer_key = YOUR-CONSUMER-KEY\n",
    "consumer_secret = YOUR-CONSUMER-SECRET\n",
    "access_token = YOUR-ACCESS-TOKEN\n",
    "access_secret = YOUR-ACCESS-SECRET\n",
    "```\n",
    "In this way you will have this information readily available to you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "import configparser\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import tweepy  # you will need to install tweepy first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the confidential token.\n",
    "credentials = configparser.ConfigParser()\n",
    "credentials.read('credentials.ini')\n",
    "\n",
    "#authentication\n",
    "auth = tweepy.OAuthHandler(credentials.get('twitter', 'consumer_key'), credentials.get('twitter', 'consumer_secret'))\n",
    "auth.set_access_token(credentials.get('twitter', 'access_token'), credentials.get('twitter', 'access_secret'))\n",
    "\n",
    "#construct API instance\n",
    "#deal with rate limits and notify when delayed because of rate limits\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are all set up to start collecting data from Twitter! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will construct a network with the following logic:\n",
    "\n",
    "1) We will chose a `user_id` in Twitter to be our first node. \n",
    "\n",
    "2) We will find (some) of the users who are both following `user_id` and are being followed by `user_id`. From now on we will call such users \"connections\" of `user_id`. We will place these user ids in a list called `first_nodes`. \n",
    "\n",
    "3) For every node in the list `first_nodes` we will then find (some) of the users who are following and are being followed by this node (aka the connections of this node). The user ids collected in this step will be placed in a list called `second_nodes`.\n",
    "\n",
    "4) The collection of the ids of all nodes (aka Twitter users) that we have collected so far will be placed in a list called `all_nodes`.\n",
    "\n",
    "5) Since we have only collected a subset of all possible \"connections\" for our nodes we have to check if there are any remaining inner connections that we have missed.\n",
    "\n",
    "The entire network is to be organized in a dictionary with entries that will have as key the Twitter id of the user (this is a number characterizing each user in Twitter) and as value the list of ids of his connections.\n",
    "\n",
    "So, let us begin. The first thing that you will have to do is to chose the node from which everything will start. I have chosen the Twitter account of [Applied Machine Learning Days](https://www.appliedmldays.org) that will take place in January 2018 in EPFL. You may change that if you wish to, but please make sure that the user you chose has both followers and friends and that he allows you to access this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'appliedmldays '\n",
    "user_id=api.get_user(user).id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell write a function that takes as an argument the Twitter id of a user and returns a list with the **ids** of his connections. Take into account the case where a user does not allow you to access this information.\n",
    "\n",
    "**Reminder:** By connections we mean users that are both followers and friends of a given user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_connections(user_id):\n",
    "    followers = []\n",
    "    friends = []\n",
    "    try:\n",
    "        for page in tweepy.Cursor(api.followers_ids, user_id).pages():\n",
    "            followers = followers + page \n",
    "        for page in tweepy.Cursor(api.friends_ids, user_id).pages():\n",
    "            friends = friends + page \n",
    "        connections = list(set(friends).intersection(followers))\n",
    "    except tweepy.TweepError: #raise exception when you cannot access the followers of a user\n",
    "        # we get a tweep error when we can't view a user - skip them and move onto the next.\n",
    "            print('Could not view user {}, skipping...'.format(user_id))\n",
    "            connections = ['null']\n",
    "    return connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_connections = find_connections(user_id)\n",
    "print('{}has {} connections'.format(user, len(first_connections)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect your `first_nodes` and `second_nodes` and organize your collected nodes and their connections in the dictionary called `network`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hints:\n",
    "* Use `random.choice([1,3,4])` to randomly choose a number in `[1, 3, 4]`.\n",
    "* Use the `append` and `remove` methods to add and remove an element from a Python list.\n",
    "* The `pop` method removes the last item in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = {}\n",
    "first_nodes = []\n",
    "second_nodes = []\n",
    "how_many = 10#This is the number of connections you are sampling. \n",
    "          #Keep small (e.g.3) for development, larger later (e.g. 10)\n",
    "n = min(how_many,len(first_connections))\n",
    "i=0\n",
    "while (i in range(0,n))&(first_connections != []):\n",
    "    current_id = random.choice(first_connections)\n",
    "    # remove the ID from the list, so we don't pick it again.\n",
    "    first_connections.remove(current_id)\n",
    "    first_nodes.append(current_id)\n",
    "    second_connections = find_connections(current_id)\n",
    "    '''avoid collecting: \n",
    "       i) protected users as first nodes \n",
    "       ii) nodes that are already collected in the second_nodes list as first nodes''' \n",
    "    if (second_connections==['null'])|(current_id in second_nodes):\n",
    "        first_nodes.pop()\n",
    "        print(i)\n",
    "        continue\n",
    "    else:\n",
    "        network[current_id] = []\n",
    "        j=0\n",
    "        m = min(how_many,len(second_connections))\n",
    "        while (j in range(0,m))&(second_connections != []):\n",
    "            new_current_id = random.choice(second_connections)\n",
    "            # remove the ID from the list, so we don't pick it again.\n",
    "            second_connections.remove(new_current_id)\n",
    "            second_nodes.append(new_current_id)\n",
    "            third_connections = find_connections(new_current_id)\n",
    "            '''avoid collecting: \n",
    "               i) protected users as second nodes \n",
    "               ii) the root node as a second node\n",
    "               ii) nodes that have already been collected in the first_nodes list as second nodes'''\n",
    "            if (third_connections==['null'])|(new_current_id==user_id)|(new_current_id in first_nodes):\n",
    "                second_nodes.pop()\n",
    "            else:\n",
    "                network[current_id].append(new_current_id)\n",
    "                j=j+1\n",
    "    \n",
    "    if user_id not in network[current_id]:\n",
    "        network[current_id].append(user_id) #make sure to include the root in the connections of the first nodes\n",
    "    print(i)\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Be careful!** You should only keep a small value for the `how_many` parameter while you are developing your code. In order to answer to the questions you should raise the value of this parameter to `how_many=10` at least. This will take a while to execute because of the API rate limit (plan your time accordingly). You should also remember to submit your jupyter notebook with the **output shown for a large value of the `how_many` parameter**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network[user_id] = first_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = network.values()\n",
    "nodes = set(val for dic in s for val in dic) \n",
    "second_nodes = list(set(second_nodes)) #remove possible duplicates from second nodes\n",
    "all_nodes = list(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are {} first hop nodes'.format(len(first_nodes)))\n",
    "print('There are {} second hop nodes'.format(len(second_nodes)))\n",
    "print('There are overall {} nodes in the collected network'.format(len(all_nodes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the dictionary entries for the second nodes \n",
    "for i in second_nodes:\n",
    "    network[i] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the inner connections between your collected nodes that you might have missed because you sampled the connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(all_nodes)):\n",
    "    current_id = all_nodes[i]\n",
    "    connections = find_connections(current_id)\n",
    "    inner_connections = []+list(set(connections).intersection(set(all_nodes)))\n",
    "    network[current_id] = list(set(network[current_id]+inner_connections))\n",
    "    print(i)\n",
    "    print(len(inner_connections))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Discover some of the properties of the collected network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Adjacency matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congradulations! You have now created a dictionary that describes a real Twitter network!\n",
    "We now want to transform this dictionary into the adjacency (or weight) matrix that you learned about in your first class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.zeros([len(all_nodes),len(all_nodes)], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_nodes = sorted(list(network.keys()))\n",
    "weights = {}\n",
    "for i in range(0,len(sorted_nodes)):\n",
    "    current_id = sorted_nodes[i]\n",
    "    weights[current_id] = sorted(network[current_id])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(sorted_nodes)):\n",
    "    current_id = sorted_nodes[i]\n",
    "    #print(current_id)\n",
    "    my_list = weights[current_id]\n",
    "    #print(my_list)\n",
    "    for j in my_list:\n",
    "        #print(j)\n",
    "        W[i,sorted_nodes.index(j)] = 1\n",
    "        W[sorted_nodes.index(j),i] = 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that a weight matrix should be symmetric. Check if it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nonzero(W-W.transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:**\n",
    "It might happen that $W \\neq W^{T} $ for some $(i,j)$. Explain why this might be the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**\n",
    "\n",
    "Your weight matrix could be non-symmetric if:\n",
    "\n",
    "* You had not chosen all of your collected nodes to be non-protected users.\n",
    "* You had not used the Cursor object in order to collect all the connections of the nodes.\n",
    "\n",
    "In this implementation, the weight matrix is created in such a way that it will always be symmetric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impose your weight matrix to be symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make W is symmetric\n",
    "bigger = W.transpose() > W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = W - W*bigger + W.transpose()*bigger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the weight matrix of your collected network.\n",
    "\n",
    "Hint: use `plt.spy()` to visualize a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.spy(W, markersize=1)\n",
    "plt.title('Adjacency Matrix W')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:**\n",
    "What is the maximum number of links $L_{max}$ in a network with $N$ nodes (where $N$ is the number of nodes in your collected network)? How many links $L$ are there in your collected network? Comment on how $L$ and $L_{max}$ compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = W.sum()/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:** The maximum number of links in a network with $N$ nodes is $L_{max}=N(N-1)/2$. This will be the case of a complete graph. Therefore, the maximum number of links for a network with $N=99$ nodes will be $L_{max}=4851$. The number of links in the collected network is $L=176$. We can see that $L << L_{max}$ and therefore we can conclude that the network is very sparse $L=O(N)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Degrees distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a histogram of the degree distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = W.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.ones_like(d)/float(len(all_nodes))\n",
    "plt.hist(d, weights = weights);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3:** Comment on the plot. What do you observe? Would you expect a similar degree disribution in the complete Twitter network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:** We observe that the majority of the nodes in the collected network have a degree equal to 1. This is not the case for the whole Twitter network, but it is a result of the way that we collected the network. \n",
    "\n",
    "However, we can see that the network seems to have a degree distribution of a scale-free network, i.e. the degree distribution follows a power law. This will become more apparent as the value of the parameter ``how_many`` increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Average degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the average degree of your collected network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_avg = np.sum(d)/len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(d_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Diameter of the collected network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4:** What is the diameter of the collected network? Please justify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:** The diameter is by definition the longest shortest path between two nodes in a network. \n",
    "\n",
    "Because of the way that we constructed the network, the longest possible paths are between two nodes of the list ``second_nodes``. \n",
    "\n",
    "Specifically, the path between any two nodes in the list ``second_nodes`` can be as in the following cases A, B, C and D :\n",
    "\n",
    "Case A:\n",
    "second node -> first node -> root -> first node -> second node\n",
    "\n",
    "Therefore, the length of the shortest path in this case will be equal to 4.\n",
    "\n",
    "Case B:\n",
    "It may happen that some of the first nodes will be connected and therefore the path between some of the second nodes will be:\n",
    "\n",
    "second node -> first node -> first node -> second node\n",
    "\n",
    "Therefore, the length of the shortest path in this case will be equal to 3.\n",
    "\n",
    "Case C:\n",
    "Some of the second nodes will obviously be connected through the same first node and therefore the path between them will be:\n",
    "\n",
    "second node -> first node -> second node\n",
    "\n",
    "Therefore, the length of the shortest path in this case will be equal to 2.\n",
    "\n",
    "Case D:\n",
    "Also it might happen that some of the second nodes will be directly connected to one another and therefore the path between those two second nodes will be second node -> second node.\n",
    "\n",
    "Therefore, the length of the shortest path in this case will be equal to 1.\n",
    "\n",
    "However, as we saw in Question 2, the collected network is very sparse and therefore at least one pair of second nodes will exist such that the shortest path between them is equal to 4. As a result, the diameter of the network will be $d=4$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Pruning the collected network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might notice that some nodes have very few connections and hence our matrix is very sparse. Prune the collected network so that you keep only the nodes that have a degree that is greater than the average degree and plot the new adjacency matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wpruned = W[d>d_avg][:,d>d_avg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.spy(Wpruned, markersize=1)\n",
    "plt.title('Adjacency Matrix W');"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
